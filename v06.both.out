'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 65.2 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │      1024] │       60] │
│ 6 │ merge             │ Sequential │ 40.7 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       188] │      128] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.6 M                                                         
Non-trainable params: 0                                                         
Total params: 1.6 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 37                                                       
Modules in eval mode: 0                                                         
Epoch 13/49 ━━━━━━━━━━━━━━━━ 218/218 0:02:21 •        1.58it/s v_num: 411e      
                                     0:00:00                   DiarizationError…
                                                               0.381            
                                                               DiarizationError…
                                                               0.088            
                                                               DiarizationError…
                                                               0.088            
                                                               DiarizationError…
                                                               0.204            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  60.15  155.05   71.16   45.89        9.37        6.04            39.43            25.43     44.46     28.68
1j20qq1JyX4_c_02                  71.49  227.81   78.19   34.32       13.25        5.82            62.78            27.56     86.84     38.12
1j20qq1JyX4_c_03                  47.48  197.26  120.23   60.95       16.62        8.43            56.66            28.72     20.37     10.33
2qQs3Y9OJX0_c_01                  67.73   89.26   43.67   48.92       14.86       16.65             5.05             5.65     40.54     45.42
2qQs3Y9OJX0_c_02                  53.98  116.06   68.83   59.30       15.42       13.28             4.23             3.64     43.01     37.06
2qQs3Y9OJX0_c_03                  36.61  147.43  113.84   77.22       20.38       13.83             8.29             5.62     25.29     17.16
4ZpjKfu6Cl8_c_01                  75.52  141.59   48.27   34.09       13.61        9.61            50.85            35.91     42.48     30.00
4ZpjKfu6Cl8_c_02                  54.93  154.92   88.16   56.91       18.34       11.84            15.47             9.99     51.28     33.10
4ZpjKfu6Cl8_c_03                  57.30  112.29   64.82   57.73       16.87       15.03             4.51             4.02     42.96     38.26
5milLu-6bWI_c_01                  35.81  174.41  115.85   66.43        3.90        2.24            32.11            18.41     26.45     15.17
5milLu-6bWI_c_02                  35.46  217.06  148.44   68.39        8.35        3.85            32.81            15.12     35.80     16.49
5milLu-6bWI_c_03                  37.55  221.49  155.41   70.17       17.09        7.72            20.64             9.32     45.44     20.52
7YpF6DntOYw_c_01                  67.45  132.86   51.48   38.74        8.23        6.19            44.65            33.61     36.74     27.65
7YpF6DntOYw_c_02                  56.08   54.12   26.96   49.82        3.19        5.90            10.75            19.87     16.40     30.31
7YpF6DntOYw_c_03                  30.56   66.24   49.20   74.27        3.20        4.83             5.67             8.56     11.37     17.17
BCiuXAuCKAU_c_01                  73.68  206.56   58.85   28.49        4.48        2.17           103.21            49.97     44.50     21.54
BCiuXAuCKAU_c_02                  43.04  154.10   95.87   62.21        8.10        5.26            29.35            19.05     28.88     18.74
BCiuXAuCKAU_c_03                  63.23  207.37   80.78   38.96        4.53        2.18            87.51            42.20     39.07     18.84
HKjR70GCRPE_c_01                  38.36  146.56  105.69   72.11       15.35       10.48             9.19             6.27     31.68     21.62
HKjR70GCRPE_c_02                  53.23  145.10   82.16   56.62       14.30        9.86            13.79             9.50     49.15     33.87
HKjR70GCRPE_c_03                  45.57  165.78  101.42   61.18       11.18        6.74            10.61             6.40     53.75     32.42
IKdBLciu_-A_c_01                  39.23  127.60   84.21   66.00        6.67        5.23            11.99             9.39     31.40     24.61
IKdBLciu_-A_c_02                  85.73   95.71   19.24   20.11        5.59        5.84            38.05            39.75     38.42     40.14
IKdBLciu_-A_c_03                  66.64   98.63   40.30   40.86        7.40        7.51            40.85            41.41     17.48     17.72
KHHgQ_Pe4cI_c_01                  56.15  180.62   83.77   46.38        4.57        2.53            90.34            50.02      6.51      3.61
KHHgQ_Pe4cI_c_02                  66.20  119.56   44.81   37.48        4.40        3.68            49.30            41.24     25.44     21.28
KHHgQ_Pe4cI_c_03                  69.58  156.28   53.20   34.04        5.67        3.63            62.41            39.93     40.67     26.02
PmElx9ZVByw_c_01                  32.45  142.53  102.28   71.76        6.01        4.22            18.45            12.95     21.80     15.29
PmElx9ZVByw_c_02                  12.49  147.22  134.59   91.42        5.76        3.91            11.35             7.71      1.28      0.87
PmElx9ZVByw_c_03                  22.82  120.01   98.07   81.71        5.44        4.53            11.28             9.40     10.67      8.89
a5mEmM6w_ks_c_01                  23.31  235.73  189.39   80.34        8.61        3.65            24.21            10.27     22.13      9.39
a5mEmM6w_ks_c_02                  17.04  185.80  163.00   87.72        8.85        4.76             7.66             4.12     15.14      8.15
a5mEmM6w_ks_c_03                  22.13  130.15  105.49   81.05        4.14        3.18            11.45             8.79     13.21     10.15
kMy-6RtoOVU_c_01                  59.51  185.77   84.29   45.37        9.06        4.88            54.45            29.31     47.04     25.32
kMy-6RtoOVU_c_02                  73.32  121.57   51.65   42.49       19.22       15.81            17.59            14.47     52.33     43.04
kMy-6RtoOVU_c_03                  56.39  111.45   64.49   57.86       15.89       14.25            14.34            12.87     32.62     29.27
qrkff49p4E4_c_01                  24.82  147.36  114.80   77.91        4.02        2.73            17.36            11.78     15.20     10.31
qrkff49p4E4_c_02                  11.66  139.38  128.18   91.96        5.05        3.62             9.86             7.07      1.35      0.97
qrkff49p4E4_c_03                  22.41  160.17  131.14   81.87        6.87        4.29            14.51             9.06     14.53      9.07
zC5Fh2tTS1U_c_01                  51.33  193.38  113.48   58.68       19.36       10.01            24.05            12.44     55.85     28.88
zC5Fh2tTS1U_c_02                  66.23  172.54   75.32   43.66       17.05        9.88            20.47            11.86     76.75     44.48
zC5Fh2tTS1U_c_03                  58.97  240.12  116.77   48.63       18.25        7.60            81.46            33.92     41.90     17.45
zR725veL-DI_c_01                  25.24  190.05  146.36   77.01        4.29        2.26            36.41            19.16      7.28      3.83
zR725veL-DI_c_02                  28.40  215.43  160.13   74.33        5.89        2.74            35.76            16.60     19.53      9.07
zR725veL-DI_c_03                  30.69  199.67  144.62   72.43        6.22        3.12            35.81            17.94     19.24      9.63
IzvOYVMltkI_c_01                  25.21  156.71  126.64   80.81        9.43        6.02            10.72             6.84     19.35     12.35
IzvOYVMltkI_c_02                  48.71  191.14  119.57   62.55       21.52       11.26            12.22             6.39     59.35     31.05
IzvOYVMltkI_c_03                  26.19  172.52  143.04   82.91       15.70        9.10             6.21             3.60     23.28     13.49
UrsCy6qIGoo_c_01                  26.07  122.69   95.00   77.43        4.29        3.50             9.41             7.67     18.27     14.90
UrsCy6qIGoo_c_02                  55.07  125.06   62.39   49.89        6.20        4.96            12.33             9.86     50.34     40.25
UrsCy6qIGoo_c_03                  39.45  197.16  124.52   63.16        5.14        2.61            14.80             7.51     57.84     29.34
yn9WN9lsHRE_c_01                  41.34  188.10  118.63   63.06        8.28        4.40            36.46            19.38     33.02     17.55
yn9WN9lsHRE_c_02                  54.50  156.18   77.49   49.62        6.43        4.12            52.45            33.58     26.24     16.80
yn9WN9lsHRE_c_03                  65.03  196.37   79.68   40.58       11.01        5.60            29.24            14.89     87.44     44.53
TOTAL                             45.85 8556.01 5165.85   60.38      532.94        6.23          1570.79            18.36   1819.38     21.26
[1;34mwandb[0m: 🚀 View run [33mmodel_4_latefuse_dihard_50e_lr1em4[0m at: [34mhttps://wandb.ai/pichenygroup/both/runs/g71t411e[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20250123_131704-g71t411e/logs[0m
