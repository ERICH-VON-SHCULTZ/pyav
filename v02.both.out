'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 65.2 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │      1024] │       60] │
│ 6 │ merge             │ Sequential │  7.3 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       120] │       60] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.5 M                                                         
Non-trainable params: 0                                                         
Total params: 1.5 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 35                                                       
Modules in eval mode: 0                                                         
Epoch 35/49 ━━━━━━━━━━━━━━━━ 218/218 0:01:15 •        2.90it/s v_num: 4r9n      
                                     0:00:00                   DiarizationError…
                                                               0.427            
                                                               DiarizationError…
                                                               0.103            
                                                               DiarizationError…
                                                               0.100            
                                                               DiarizationError…
                                                               0.223            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  50.73  155.05   85.63   55.23        9.24        5.96            41.24            26.60     28.18     18.17
1j20qq1JyX4_c_02                  71.40  227.81   79.53   34.91       14.37        6.31            63.36            27.81     84.92     37.28
1j20qq1JyX4_c_03                  48.36  197.26  120.96   61.32       19.10        9.68            52.84            26.79     23.45     11.89
2qQs3Y9OJX0_c_01                  67.08   89.26   51.83   58.07       22.45       25.15             4.48             5.02     32.94     36.91
2qQs3Y9OJX0_c_02                  67.78  116.06   61.44   52.94       24.05       20.72             3.61             3.11     51.02     43.96
2qQs3Y9OJX0_c_03                  42.30  147.43  108.99   73.93       23.92       16.23             6.77             4.59     31.66     21.48
4ZpjKfu6Cl8_c_01                  75.86  141.59   49.03   34.62       14.85       10.49            49.27            34.80     43.30     30.58
4ZpjKfu6Cl8_c_02                  54.56  154.92   87.33   56.37       16.93       10.93            24.45            15.78     43.14     27.85
4ZpjKfu6Cl8_c_03                  55.61  112.29   62.54   55.69       12.69       11.30            11.07             9.86     38.68     34.45
5milLu-6bWI_c_01                  36.53  174.41  114.56   65.68        3.86        2.22            41.76            23.94     18.10     10.38
5milLu-6bWI_c_02                  41.97  217.06  135.94   62.63        9.98        4.60            34.42            15.86     46.69     21.51
5milLu-6bWI_c_03                  44.24  221.49  134.99   60.95       11.49        5.19            31.46            14.20     55.04     24.85
7YpF6DntOYw_c_01                  67.26  132.86   51.48   38.75        7.98        6.01            40.66            30.60     40.73     30.65
7YpF6DntOYw_c_02                  57.12   54.12   25.63   47.37        2.43        4.49            12.08            22.32     16.40     30.31
7YpF6DntOYw_c_03                  26.91   66.24   52.03   78.55        3.62        5.46             4.53             6.84      9.68     14.61
BCiuXAuCKAU_c_01                  78.71  206.56   46.26   22.39        2.28        1.10           139.38            67.48     20.92     10.13
BCiuXAuCKAU_c_02                  39.37  154.10  100.89   65.47        7.45        4.84            32.45            21.06     20.77     13.48
BCiuXAuCKAU_c_03                  64.44  207.37   76.31   36.80        2.58        1.24           108.31            52.23     22.75     10.97
HKjR70GCRPE_c_01                  36.79  146.56  102.88   70.20       10.24        6.99            23.55            16.07     20.12     13.73
HKjR70GCRPE_c_02                  47.65  145.10   85.22   58.73        9.25        6.38            26.85            18.50     33.04     22.77
HKjR70GCRPE_c_03                  46.33  165.78   99.14   59.80       10.16        6.13            13.89             8.38     52.75     31.82
IKdBLciu_-A_c_01                  37.27  127.60   88.98   69.74        8.94        7.01            12.07             9.46     26.55     20.80
IKdBLciu_-A_c_02                  69.20   95.71   34.74   36.30        5.26        5.50            39.66            41.44     21.30     22.26
IKdBLciu_-A_c_03                  72.25   98.63   32.12   32.57        4.76        4.83            49.22            49.90     17.28     17.52
KHHgQ_Pe4cI_c_01                  57.21  180.62   81.43   45.08        4.13        2.29            92.13            51.00      7.07      3.91
KHHgQ_Pe4cI_c_02                  68.94  119.56   42.18   35.28        5.04        4.21            55.83            46.70     21.55     18.03
KHHgQ_Pe4cI_c_03                  67.55  156.28   56.06   35.87        5.35        3.42            67.20            43.00     33.02     21.13
PmElx9ZVByw_c_01                  36.98  142.53  101.12   70.95       11.30        7.93            16.62            11.66     24.79     17.39
PmElx9ZVByw_c_02                  12.44  147.22  135.93   92.33        7.02        4.77             9.97             6.77      1.33      0.90
PmElx9ZVByw_c_03                  21.53  120.01  100.06   83.38        5.89        4.91            11.06             9.22      8.88      7.40
a5mEmM6w_ks_c_01                  26.38  235.73  183.74   77.95       10.21        4.33            22.85             9.69     29.13     12.36
a5mEmM6w_ks_c_02                  30.21  185.80  135.73   73.05        6.04        3.25            35.60            19.16     14.48      7.79
a5mEmM6w_ks_c_03                  22.14  130.15  106.94   82.16        5.60        4.30            10.04             7.71     13.18     10.13
kMy-6RtoOVU_c_01                  55.24  185.77   91.87   49.45        8.72        4.69            63.32            34.08     30.59     16.46
kMy-6RtoOVU_c_02                  64.82  121.57   63.22   52.00       20.46       16.83            19.38            15.94     38.97     32.06
kMy-6RtoOVU_c_03                  66.73  111.45   48.21   43.25       11.12        9.98            17.41            15.62     45.84     41.13
qrkff49p4E4_c_01                  24.61  147.36  115.08   78.10        3.99        2.71            16.88            11.46     15.39     10.44
qrkff49p4E4_c_02                  14.76  139.38  124.13   89.05        5.32        3.82            10.13             7.27      5.13      3.68
qrkff49p4E4_c_03                  44.11  160.17   96.85   60.47        7.33        4.58            15.18             9.48     48.14     30.06
zC5Fh2tTS1U_c_01                  54.86  193.38  134.76   69.69       47.46       24.54            18.85             9.75     39.77     20.56
zC5Fh2tTS1U_c_02                  73.68  172.54   65.08   37.72       19.67       11.40            25.72            14.91     81.73     47.37
zC5Fh2tTS1U_c_03                  59.76  240.12  117.40   48.89       20.77        8.65            72.65            30.25     50.08     20.86
zR725veL-DI_c_01                  37.46  190.05  125.67   66.12        6.81        3.58            34.24            18.02     30.14     15.86
zR725veL-DI_c_02                  27.30  215.43  162.56   75.46        5.95        2.76            36.78            17.07     16.09      7.47
zR725veL-DI_c_03                  30.74  199.67  145.96   73.10        7.67        3.84            32.34            16.19     21.38     10.71
IzvOYVMltkI_c_01                  32.19  156.71  115.02   73.39        8.75        5.58            12.64             8.07     29.06     18.54
IzvOYVMltkI_c_02                  31.55  191.14  150.12   78.54       19.28       10.09            16.68             8.73     24.33     12.73
IzvOYVMltkI_c_03                  31.01  172.52  132.03   76.53       13.00        7.54             7.39             4.29     33.10     19.19
UrsCy6qIGoo_c_01                  39.38  122.69   77.76   63.38        3.39        2.77            32.16            26.21     12.77     10.41
UrsCy6qIGoo_c_02                  49.23  125.06   70.21   56.14        6.72        5.37            10.85             8.68     44.00     35.18
UrsCy6qIGoo_c_03                  39.80  197.16  124.96   63.38        6.27        3.18            14.73             7.47     57.46     29.15
yn9WN9lsHRE_c_01                  45.68  188.10  108.85   57.87        6.67        3.54            52.01            27.65     27.25     14.48
yn9WN9lsHRE_c_02                  48.70  156.18   89.09   57.05        8.98        5.75            56.67            36.28     10.42      6.67
yn9WN9lsHRE_c_03                  58.72  196.37   93.13   47.43       12.06        6.14            31.82            16.20     71.42     36.37
TOTAL                             47.23 8556.01 5083.62   59.42      568.88        6.65          1786.51            20.88   1685.88     19.70
[1;34mwandb[0m: 🚀 View run [33mmodel_0_dihard_50e_lr1em4[0m at: [34mhttps://wandb.ai/pichenygroup/both/runs/66so4r9n[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20250121_100132-66so4r9n/logs[0m
