'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database_new.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 65.2 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │      1024] │       60] │
│ 6 │ merge             │ Sequential │  7.3 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       120] │       60] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.5 M                                                         
Non-trainable params: 0                                                         
Total params: 1.5 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 35                                                       
Modules in eval mode: 0                                                         
Epoch 12/49 ━━━━━━━━━━━━━━━━ 218/218 0:03:01 •        1.17it/s v_num: y18m      
                                     0:00:00                   DiarizationError…
                                                               0.823            
                                                               DiarizationError…
                                                               0.122            
                                                               DiarizationError…
                                                               0.288            
                                                               DiarizationError…
                                                               0.412            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  71.65  155.04   57.37   37.00       13.42        8.65            56.03            36.14     41.64     26.86
1j20qq1JyX4_c_02                  77.14  227.61   69.35   30.47       17.33        7.62            72.63            31.91     85.62     37.62
1j20qq1JyX4_c_03                  53.98  197.25  119.19   60.43       28.43       14.41            54.53            27.64     23.52     11.93
2qQs3Y9OJX0_c_01                 141.70   88.76   29.09   32.77       66.10       74.47            29.53            33.27     30.14     33.96
2qQs3Y9OJX0_c_02                  75.18  115.94   54.09   46.66       25.32       21.84             8.26             7.13     53.58     46.22
2qQs3Y9OJX0_c_03                  59.17  147.42   85.53   58.02       25.34       17.19            24.61            16.69     37.28     25.29
4ZpjKfu6Cl8_c_01                  75.54  141.58   55.45   39.16       20.82       14.71            41.80            29.52     44.33     31.31
4ZpjKfu6Cl8_c_02                  74.45  154.91   59.34   38.31       19.76       12.76            36.82            23.77     58.74     37.92
4ZpjKfu6Cl8_c_03                  84.76  112.18   33.35   29.73       16.26       14.49            14.84            13.23     63.99     57.04
5milLu-6bWI_c_01                  86.10  172.09   65.28   37.94       41.37       24.04            73.14            42.50     33.66     19.56
5milLu-6bWI_c_02                  49.98  217.04  122.42   56.41       13.87        6.39            52.98            24.41     41.64     19.18
5milLu-6bWI_c_03                  49.45  221.47  127.45   57.54       15.50        7.00            51.24            23.14     42.78     19.32
7YpF6DntOYw_c_01                 106.22  130.38   24.67   18.92       32.78       25.14            89.41            68.57     16.31     12.51
7YpF6DntOYw_c_02                 126.12   47.97    2.60    5.41       15.12       31.53            42.22            88.01      3.16      6.58
7YpF6DntOYw_c_03                 128.61   63.64   15.90   24.98       34.10       53.59            43.44            68.26      4.31      6.77
BCiuXAuCKAU_c_01                 101.87  204.14   20.81   10.20       24.63       12.06           162.38            79.54     20.94     10.26
BCiuXAuCKAU_c_02                 109.72  151.16   36.26   23.99       50.95       33.71            84.22            55.71     30.68     20.30
BCiuXAuCKAU_c_03                  78.18  207.35   49.34   23.80        4.11        1.98           113.43            54.71     44.58     21.50
HKjR70GCRPE_c_01                  42.94  146.55  108.90   74.31       25.28       17.25            22.72            15.51     14.93     10.19
HKjR70GCRPE_c_02                  65.22  145.09   81.78   56.36       31.32       21.59            17.55            12.09     45.76     31.54
HKjR70GCRPE_c_03                  58.41  165.77   88.48   53.37       19.53       11.78            20.28            12.23     57.01     34.39
IKdBLciu_-A_c_01                  49.58  127.59   75.60   59.25       11.27        8.84            29.46            23.09     22.53     17.65
IKdBLciu_-A_c_02                  98.38   95.14   14.33   15.07       12.79       13.44            62.40            65.59     18.41     19.35
IKdBLciu_-A_c_03                  78.38   98.48   30.17   30.64        8.88        9.02            49.33            50.09     18.98     19.27
KHHgQ_Pe4cI_c_01                  99.44  173.06   35.67   20.61       34.70       20.05           112.48            65.00     24.90     14.39
KHHgQ_Pe4cI_c_02                 125.15  111.72   13.76   12.32       41.86       37.47            86.70            77.60     11.26     10.07
KHHgQ_Pe4cI_c_03                 107.00  155.64   26.48   17.01       37.37       24.01            99.24            63.76     29.92     19.22
PmElx9ZVByw_c_01                 110.02  140.52   64.03   45.57       78.11       55.59            63.01            44.84     13.48      9.59
PmElx9ZVByw_c_02                  50.21  146.74  102.95   70.16       29.88       20.37            29.78            20.29     14.01      9.55
PmElx9ZVByw_c_03                  64.80  119.72   66.14   55.24       24.00       20.04            22.20            18.54     31.38     26.21
a5mEmM6w_ks_c_01                  70.38  233.82  114.42   48.93       45.17       19.32            67.31            28.79     52.10     22.28
a5mEmM6w_ks_c_02                  47.75  185.77  107.13   57.67       10.07        5.42            42.03            22.62     36.61     19.71
a5mEmM6w_ks_c_03                 124.50  127.45   31.54   24.74       62.76       49.24            68.61            53.83     27.31     21.42
kMy-6RtoOVU_c_01                  63.72  185.74   76.62   41.25        9.24        4.97            75.13            40.45     33.99     18.30
kMy-6RtoOVU_c_02                  68.16  121.56   55.38   45.56       16.68       13.72            36.29            29.86     29.89     24.59
kMy-6RtoOVU_c_03                  73.34  111.44   40.89   36.69       11.18       10.03            34.04            30.55     36.51     32.76
qrkff49p4E4_c_01                  35.75  147.35  100.46   68.18        5.78        3.93            30.64            20.79     16.25     11.03
qrkff49p4E4_c_02                  28.47  139.30  104.06   74.70        4.41        3.17            21.76            15.62     13.48      9.68
qrkff49p4E4_c_03                  47.11  160.16   95.12   59.39       10.41        6.50            26.83            16.75     38.22     23.86
zC5Fh2tTS1U_c_01                 113.62  182.11   58.96   32.38       83.77       46.00            48.09            26.41     75.06     41.21
zC5Fh2tTS1U_c_02                  92.52  172.52   61.96   35.91       49.06       28.43            24.92            14.44     85.65     49.64
zC5Fh2tTS1U_c_03                  77.44  240.11   89.44   37.25       35.26       14.69            58.01            24.16     92.67     38.59
zR725veL-DI_c_01                  68.41  189.63   89.52   47.21       29.62       15.62            49.37            26.04     50.73     26.75
zR725veL-DI_c_02                  65.08  215.42   88.55   41.10       13.32        6.19            40.37            18.74     86.50     40.16
zR725veL-DI_c_03                  70.51  199.66   73.23   36.68       14.35        7.18            40.59            20.33     85.85     43.00
IzvOYVMltkI_c_01                  64.27  156.33   84.66   54.16       28.81       18.43            27.17            17.38     44.49     28.46
IzvOYVMltkI_c_02                  57.64  191.12  111.91   58.55       30.94       16.19            18.90             9.89     60.31     31.56
IzvOYVMltkI_c_03                  55.05  172.51  102.29   59.30       24.76       14.35            15.25             8.84     54.97     31.86
UrsCy6qIGoo_c_01                  65.36  122.67   45.97   37.48        3.48        2.84            46.62            38.01     30.07     24.52
UrsCy6qIGoo_c_02                  63.07  124.94   53.34   42.69        7.20        5.76            24.20            19.37     47.40     37.94
UrsCy6qIGoo_c_03                  48.78  197.14  111.51   56.56       10.53        5.34            22.03            11.17     63.61     32.26
yn9WN9lsHRE_c_01                  59.79  188.08   87.61   46.58       11.99        6.37            51.62            27.45     48.85     25.97
yn9WN9lsHRE_c_02                  65.84  156.16   61.15   39.16        7.81        5.00            72.57            46.47     22.44     14.37
yn9WN9lsHRE_c_03                  68.66  196.36   79.63   40.56       18.09        9.21            37.63            19.16     79.09     40.28
TOTAL                             72.98 8499.30 3661.12   43.08     1364.88       16.06          2646.64            31.14   2191.54     25.78
[1;34mwandb[0m: 🚀 View run [33mmodel_0_dihard_50e_lr1em4[0m at: [34mhttps://wandb.ai/pichenygroup/both/runs/0363y18m[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20250929_211404-0363y18m/logs[0m
