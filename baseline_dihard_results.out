'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 65.2 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │      1024] │       60] │
│ 6 │ merge             │ Sequential │  7.3 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       120] │       60] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.5 M                                                         
Non-trainable params: 0                                                         
Total params: 1.5 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 35                                                       
Modules in eval mode: 0                                                         
Epoch 27/49 ━━━━━━━━━━━━━━━━ 218/218 0:02:10 •        1.69it/s v_num: 2ukf      
                                     0:00:00                   DiarizationError…
                                                               0.375            
                                                               DiarizationError…
                                                               0.092            
                                                               DiarizationError…
                                                               0.091            
                                                               DiarizationError…
                                                               0.193            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  56.70  155.05   78.84   50.85       11.71        7.55            38.20            24.64     38.00     24.51
1j20qq1JyX4_c_02                  71.40  227.81   79.53   34.91       14.39        6.32            60.08            26.37     88.20     38.72
1j20qq1JyX4_c_03                  48.68  197.26  118.98   60.31       17.75        9.00            53.99            27.37     24.30     12.32
2qQs3Y9OJX0_c_01                  68.63   89.26   48.28   54.10       20.28       22.72             3.38             3.78     37.59     42.12
2qQs3Y9OJX0_c_02                  55.16  116.06   71.24   61.38       19.19       16.53             3.10             2.67     41.72     35.95
2qQs3Y9OJX0_c_03                  40.57  147.43  110.29   74.81       22.67       15.38             6.58             4.46     30.56     20.73
4ZpjKfu6Cl8_c_01                  71.70  141.59   55.56   39.24       15.49       10.94            49.64            35.06     36.40     25.71
4ZpjKfu6Cl8_c_02                  55.62  154.92   89.51   57.78       20.76       13.40            15.91            10.27     49.49     31.95
4ZpjKfu6Cl8_c_03                  58.57  112.29   65.67   58.48       19.14       17.05             4.38             3.90     42.24     37.62
5milLu-6bWI_c_01                  35.63  174.41  116.64   66.87        4.36        2.50            32.65            18.72     25.12     14.40
5milLu-6bWI_c_02                  37.29  217.06  146.35   67.42       10.22        4.71            30.47            14.04     40.24     18.54
5milLu-6bWI_c_03                  37.35  221.49  158.82   71.71       20.06        9.06            18.09             8.17     44.58     20.13
7YpF6DntOYw_c_01                  69.74  132.86   52.45   39.48       12.24        9.21            41.69            31.38     38.72     29.14
7YpF6DntOYw_c_02                  59.23   54.12   25.76   47.61        3.70        6.83             9.94            18.37     18.41     34.02
7YpF6DntOYw_c_03                  29.28   66.24   50.55   76.31        3.70        5.59             4.21             6.36     11.48     17.33
BCiuXAuCKAU_c_01                  74.57  206.56   59.23   28.67        6.71        3.25            98.10            47.49     49.24     23.84
BCiuXAuCKAU_c_02                  42.22  154.10   99.32   64.45       10.28        6.67            26.59            17.26     28.18     18.29
BCiuXAuCKAU_c_03                  59.91  207.37   89.30   43.06        6.16        2.97            86.43            41.68     31.64     15.26
HKjR70GCRPE_c_01                  38.10  146.56  106.88   72.93       16.16       11.03             9.31             6.35     30.37     20.72
HKjR70GCRPE_c_02                  51.81  145.10   85.51   58.93       15.58       10.74            12.69             8.74     46.91     32.33
HKjR70GCRPE_c_03                  53.31  165.78   89.70   54.11       12.30        7.42             8.84             5.33     67.23     40.56
IKdBLciu_-A_c_01                  39.24  127.60   86.45   67.75        8.92        6.99             8.76             6.86     32.39     25.38
IKdBLciu_-A_c_02                  83.27   95.71   23.80   24.87        7.79        8.14            32.37            33.82     39.54     41.31
IKdBLciu_-A_c_03                  75.67   98.63   32.63   33.08        8.63        8.75            37.96            38.49     28.04     28.43
KHHgQ_Pe4cI_c_01                  57.31  180.62   82.62   45.74        5.51        3.05            87.72            48.57     10.29      5.69
KHHgQ_Pe4cI_c_02                  67.83  119.56   44.25   37.01        5.79        4.84            47.21            39.49     28.10     23.50
KHHgQ_Pe4cI_c_03                  65.41  156.28   62.36   39.90        8.29        5.31            59.36            37.98     34.57     22.12
PmElx9ZVByw_c_01                  30.99  142.53  106.71   74.87        8.35        5.86            13.79             9.68     22.03     15.46
PmElx9ZVByw_c_02                  11.97  147.22  135.54   92.07        5.94        4.04            10.33             7.02      1.35      0.91
PmElx9ZVByw_c_03                  20.74  120.01  101.03   84.19        5.92        4.93             9.98             8.32      8.99      7.49
a5mEmM6w_ks_c_01                  23.32  235.73  191.50   81.24       10.74        4.55            19.73             8.37     24.50     10.39
a5mEmM6w_ks_c_02                  16.18  185.80  165.46   89.05        9.72        5.23             6.31             3.39     14.04      7.56
a5mEmM6w_ks_c_03                  21.46  130.15  107.97   82.96        5.74        4.41             9.03             6.94     13.15     10.10
kMy-6RtoOVU_c_01                  62.79  185.77   81.17   43.69       12.03        6.48            49.24            26.50     55.37     29.80
kMy-6RtoOVU_c_02                  64.60  121.57   63.16   51.95       20.13       16.56            19.85            16.32     38.57     31.72
kMy-6RtoOVU_c_03                  59.56  111.45   64.46   57.84       19.39       17.40            12.91            11.58     34.08     30.58
qrkff49p4E4_c_01                  17.23  147.36  126.61   85.92        4.64        3.15            16.37            11.11      4.37      2.97
qrkff49p4E4_c_02                  13.87  139.38  125.51   90.05        5.46        3.92             9.17             6.58      4.71      3.38
qrkff49p4E4_c_03                  23.55  160.17  130.65   81.57        8.20        5.12            13.06             8.15     16.47     10.28
zC5Fh2tTS1U_c_01                  44.19  193.38  126.49   65.41       18.56        9.60            23.71            12.26     43.19     22.33
zC5Fh2tTS1U_c_02                  60.43  172.54   85.66   49.65       17.39       10.08            20.65            11.97     66.22     38.38
zC5Fh2tTS1U_c_03                  59.49  240.12  118.48   49.34       21.21        8.83            82.18            34.22     39.47     16.44
zR725veL-DI_c_01                  23.85  190.05  150.00   78.93        5.27        2.77            32.83            17.28      7.22      3.80
zR725veL-DI_c_02                  28.28  215.43  162.13   75.26        7.61        3.53            33.08            15.36     20.22      9.39
zR725veL-DI_c_03                  29.30  199.67  148.13   74.18        6.96        3.48            32.60            16.33     18.95      9.49
IzvOYVMltkI_c_01                  24.65  156.71  128.17   81.79       10.09        6.44             9.97             6.36     18.57     11.85
IzvOYVMltkI_c_02                  53.59  191.14  114.39   59.85       25.68       13.44            10.89             5.70     65.86     34.46
IzvOYVMltkI_c_03                  29.95  172.52  136.36   79.04       15.50        8.99             4.95             2.87     31.21     18.09
UrsCy6qIGoo_c_01                  26.08  122.69   95.41   77.76        4.72        3.85             8.22             6.70     19.06     15.54
UrsCy6qIGoo_c_02                  56.83  125.06   61.45   49.14        7.46        5.97            10.67             8.53     52.94     42.33
UrsCy6qIGoo_c_03                  36.22  197.16  133.41   67.67        7.66        3.88            11.80             5.98     51.95     26.35
yn9WN9lsHRE_c_01                  40.38  188.10  120.63   64.13        8.48        4.51            35.28            18.75     32.19     17.11
yn9WN9lsHRE_c_02                  43.13  156.18   94.62   60.58        5.81        3.72            53.73            34.40      7.83      5.01
yn9WN9lsHRE_c_03                  67.34  196.37   77.37   39.40       13.24        6.74            23.04            11.73     95.95     48.86
TOTAL                             45.50 8556.01 5282.99   61.75      619.69        7.24          1471.00            17.19   1802.03     21.06
[1;34mwandb[0m: 🚀 View run [33mmodel_0_dihard_50e_lr1em4[0m at: [34mhttps://wandb.ai/pichenygroup/both/runs/tixv2ukf[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20250120_230826-tixv2ukf/logs[0m
