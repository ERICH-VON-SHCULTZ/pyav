'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.new2.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 26.8 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │       384] │       60] │
│ 6 │ merge             │ Sequential │  7.3 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       120] │       60] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.5 M                                                         
Non-trainable params: 0                                                         
Total params: 1.5 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 35                                                       
Modules in eval mode: 0                                                         
Epoch 30/49 ━━━━━━━━━━━━━━━━ 218/218 0:00:33 •        6.91it/s v_num: wnyk      
                                     0:00:00                   DiarizationError…
                                                               0.450            
                                                               DiarizationError…
                                                               0.111            
                                                               DiarizationError…
                                                               0.119            
                                                               DiarizationError…
                                                               0.220            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  60.15  155.04   71.33   46.01        9.55        6.16            43.01            27.74     40.70     26.25
1j20qq1JyX4_c_02                  69.79  227.80   83.28   36.56       14.47        6.35            64.51            28.32     80.02     35.13
1j20qq1JyX4_c_03                  47.96  197.25  122.52   62.12       19.87       10.08            48.98            24.83     25.75     13.05
2qQs3Y9OJX0_c_01                  81.85   89.25   44.65   50.03       28.45       31.88             5.13             5.75     39.47     44.22
2qQs3Y9OJX0_c_02                  65.58  116.05   63.47   54.69       23.52       20.27             3.95             3.40     48.63     41.91
2qQs3Y9OJX0_c_03                  41.05  147.42  111.34   75.53       24.43       16.57             5.88             3.99     30.20     20.48
4ZpjKfu6Cl8_c_01                  77.48  141.59   46.42   32.79       14.54       10.27            55.75            39.38     39.41     27.84
4ZpjKfu6Cl8_c_02                  60.74  154.91   76.59   49.44       15.77       10.18            25.27            16.31     53.05     34.24
4ZpjKfu6Cl8_c_03                  57.00  112.28   60.15   53.57       11.87       10.57            12.42            11.06     39.71     35.36
5milLu-6bWI_c_01                  40.38  174.40  113.07   64.83        9.08        5.21            37.45            21.47     23.89     13.70
5milLu-6bWI_c_02                  50.97  217.04  119.84   55.21       13.41        6.18            34.20            15.76     63.01     29.03
5milLu-6bWI_c_03                  52.96  221.48  127.09   57.38       22.90       10.34            26.91            12.15     67.48     30.47
7YpF6DntOYw_c_01                  71.99  132.86   45.63   34.34        8.42        6.33            47.09            35.45     40.14     30.21
7YpF6DntOYw_c_02                  51.58   54.11   28.99   53.57        2.79        5.16            10.73            19.82     14.39     26.60
7YpF6DntOYw_c_03                  37.53   66.22   44.75   67.58        3.38        5.11             5.80             8.76     15.67     23.66
BCiuXAuCKAU_c_01                  75.25  206.55   56.40   27.31        5.27        2.55           116.57            56.44     33.57     16.26
BCiuXAuCKAU_c_02                  43.82  154.09   96.64   62.71       10.06        6.53            24.14            15.67     33.31     21.62
BCiuXAuCKAU_c_03                  57.19  207.36   94.30   45.48        5.53        2.67            90.00            43.41     23.06     11.12
HKjR70GCRPE_c_01                  41.29  146.55   98.98   67.54       12.94        8.83            25.44            17.36     22.13     15.10
HKjR70GCRPE_c_02                  51.50  145.09   83.52   57.57       13.15        9.06            16.83            11.60     44.74     30.84
HKjR70GCRPE_c_03                  55.29  165.77   83.05   50.10        8.94        5.39            15.63             9.43     67.10     40.48
IKdBLciu_-A_c_01                  40.50  127.59   87.15   68.31       11.24        8.81            10.34             8.11     30.09     23.59
IKdBLciu_-A_c_02                  78.67   95.70   29.98   31.33        9.58       10.01            34.63            36.19     31.08     32.47
IKdBLciu_-A_c_03                  72.87   98.62   35.22   35.72        8.46        8.58            40.43            40.99     22.97     23.29
KHHgQ_Pe4cI_c_01                  59.84  180.62   77.89   43.12        5.35        2.96            93.78            51.92      8.95      4.96
KHHgQ_Pe4cI_c_02                  81.63  119.55   29.03   24.28        7.07        5.91            55.91            46.77     34.61     28.95
KHHgQ_Pe4cI_c_03                  70.13  156.27   53.01   33.92        6.33        4.05            67.56            43.24     35.70     22.84
PmElx9ZVByw_c_01                  38.78  142.52  100.26   70.35       13.02        9.13            21.11            14.81     21.15     14.84
PmElx9ZVByw_c_02                  13.61  147.21  134.89   91.63        7.72        5.25            10.57             7.18      1.76      1.19
PmElx9ZVByw_c_03                  29.03  120.00   92.42   77.02        7.27        6.06             9.32             7.77     18.25     15.21
a5mEmM6w_ks_c_01                  31.44  235.72  171.88   72.92       10.26        4.35            25.66            10.89     38.18     16.20
a5mEmM6w_ks_c_02                  34.04  185.79  128.38   69.10        5.84        3.14            35.59            19.15     21.82     11.75
a5mEmM6w_ks_c_03                  24.03  130.15  106.32   81.69        7.44        5.72             9.61             7.38     14.22     10.93
kMy-6RtoOVU_c_01                  57.75  185.76   87.80   47.26        9.31        5.01            58.00            31.22     39.97     21.52
kMy-6RtoOVU_c_02                  67.09  121.56   57.17   47.02       17.16       14.12            21.26            17.49     43.14     35.49
kMy-6RtoOVU_c_03                  54.75  111.44   61.45   55.14       11.02        9.89            18.87            16.93     31.12     27.92
qrkff49p4E4_c_01                  26.15  147.35  113.10   76.76        4.29        2.91            18.79            12.75     15.45     10.49
qrkff49p4E4_c_02                  12.85  139.37  126.87   91.03        5.41        3.88            10.80             7.75      1.71      1.22
qrkff49p4E4_c_03                  25.95  160.16  126.52   79.00        7.93        4.95            15.44             9.64     18.20     11.36
zC5Fh2tTS1U_c_01                  47.87  193.37  123.47   63.85       22.67       11.72            24.90            12.88     45.00     23.27
zC5Fh2tTS1U_c_02                  74.68  172.53   64.78   37.55       21.09       12.22            28.34            16.43     79.41     46.03
zC5Fh2tTS1U_c_03                  67.27  240.11  106.15   44.21       27.55       11.47            58.97            24.56     75.00     31.23
zR725veL-DI_c_01                  31.69  190.04  135.96   71.54        6.15        3.24            34.83            18.33     19.25     10.13
zR725veL-DI_c_02                  34.23  215.42  149.71   69.50        8.04        3.73            39.13            18.17     26.57     12.33
zR725veL-DI_c_03                  33.47  199.67  140.26   70.24        7.42        3.71            33.47            16.76     25.94     12.99
IzvOYVMltkI_c_01                  33.45  156.70  115.48   73.69       11.20        7.15            12.58             8.03     28.64     18.28
IzvOYVMltkI_c_02                  54.23  191.13  108.44   56.74       20.96       10.97            14.60             7.64     68.09     35.62
IzvOYVMltkI_c_03                  29.27  172.51  138.87   80.50       16.84        9.76             6.92             4.01     26.73     15.49
UrsCy6qIGoo_c_01                  50.89  122.68   62.88   51.25        2.62        2.14            43.88            35.77     15.92     12.98
UrsCy6qIGoo_c_02                  58.24  125.05   57.98   46.37        5.76        4.61            12.71            10.16     54.36     43.47
UrsCy6qIGoo_c_03                  35.61  197.15  133.96   67.95        7.02        3.56            13.14             6.67     50.04     25.38
yn9WN9lsHRE_c_01                  40.28  188.09  118.83   63.18        6.50        3.46            43.52            23.14     25.74     13.68
yn9WN9lsHRE_c_02                  54.70  156.16   77.92   49.90        7.17        4.59            56.89            36.43     21.35     13.67
yn9WN9lsHRE_c_03                  63.89  196.36   82.94   42.24       12.04        6.13            29.50            15.02     83.92     42.74
TOTAL                             49.82 8555.43 4908.95   57.38      616.09        7.20          1726.72            20.18   1919.75     22.44
[1;34mwandb[0m: 🚀 View run [33mmodel_0_dihard_50e_lr1em4_2[0m at: [34mhttps://wandb.ai/pichenygroup/both13/runs/4i6qwnyk[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20251006_134602-4i6qwnyk/logs[0m
