'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
'AVA-AVD.SpeakerDiarization.data' found in /scratch/map22-share/pyav/database.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.
***************ORIGINAL MODEL****************
***************MODIFIED MODEL****************
Protocol AVA-AVD.SpeakerDiarization.data does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.
┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┓
┃   ┃ Name              ┃ Type       ┃ Params ┃ Mode  ┃   In sizes ┃ Out sizes ┃
┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━┩
│ 0 │ sincnet           │ SincNet    │ 42.6 K │ train │     [1, 1, │   [1, 60, │
│   │                   │            │        │       │    160000] │      589] │
│ 1 │ lstm              │ LSTM       │  1.4 M │ train │   [1, 589, │ [[1, 589, │
│   │                   │            │        │       │        60] │     256], │
│   │                   │            │        │       │            │   [[8, 1, │
│   │                   │            │        │       │            │ 128], [8, │
│   │                   │            │        │       │            │ 1, 128]]] │
│ 2 │ linear            │ ModuleList │ 49.4 K │ train │          ? │         ? │
│ 3 │ classifier        │ Linear     │    903 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       128] │        7] │
│ 4 │ activation        │ LogSoftmax │      0 │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │         7] │        7] │
│ 5 │ second_input      │ Sequential │ 65.2 K │ train │   [1, 300, │  [1, 300, │
│   │                   │            │        │       │      1024] │       60] │
│ 6 │ merge             │ Sequential │ 10.9 K │ train │   [1, 589, │  [1, 589, │
│   │                   │            │        │       │       120] │       60] │
│ 7 │ powerset          │ Powerset   │      0 │ train │          ? │         ? │
│ 8 │ validation_metric │ MetricCol… │      0 │ train │          ? │         ? │
└───┴───────────────────┴────────────┴────────┴───────┴────────────┴───────────┘
Trainable params: 1.5 M                                                         
Non-trainable params: 0                                                         
Total params: 1.5 M                                                             
Total estimated model params size (MB): 6                                       
Modules in train mode: 37                                                       
Modules in eval mode: 0                                                         
Epoch 41/49 ━━━━━━━━━━━━━━━━ 218/218 0:02:16 •        1.69it/s v_num: fhq1      
                                     0:00:00                   DiarizationError…
                                                               0.449            
                                                               DiarizationError…
                                                               0.117            
                                                               DiarizationError…
                                                               0.107            
                                                               DiarizationError…
                                                               0.224            
1j20qq1JyX4_c_01
1j20qq1JyX4_c_02
1j20qq1JyX4_c_03
2qQs3Y9OJX0_c_01
2qQs3Y9OJX0_c_02
2qQs3Y9OJX0_c_03
4ZpjKfu6Cl8_c_01
4ZpjKfu6Cl8_c_02
4ZpjKfu6Cl8_c_03
5milLu-6bWI_c_01
5milLu-6bWI_c_02
5milLu-6bWI_c_03
7YpF6DntOYw_c_01
7YpF6DntOYw_c_02
7YpF6DntOYw_c_03
BCiuXAuCKAU_c_01
BCiuXAuCKAU_c_02
BCiuXAuCKAU_c_03
HKjR70GCRPE_c_01
HKjR70GCRPE_c_02
HKjR70GCRPE_c_03
IKdBLciu_-A_c_01
IKdBLciu_-A_c_02
IKdBLciu_-A_c_03
KHHgQ_Pe4cI_c_01
KHHgQ_Pe4cI_c_02
KHHgQ_Pe4cI_c_03
PmElx9ZVByw_c_01
PmElx9ZVByw_c_02
PmElx9ZVByw_c_03
a5mEmM6w_ks_c_01
a5mEmM6w_ks_c_02
a5mEmM6w_ks_c_03
kMy-6RtoOVU_c_01
kMy-6RtoOVU_c_02
kMy-6RtoOVU_c_03
qrkff49p4E4_c_01
qrkff49p4E4_c_02
qrkff49p4E4_c_03
zC5Fh2tTS1U_c_01
zC5Fh2tTS1U_c_02
zC5Fh2tTS1U_c_03
zR725veL-DI_c_01
zR725veL-DI_c_02
zR725veL-DI_c_03
IzvOYVMltkI_c_01
IzvOYVMltkI_c_02
IzvOYVMltkI_c_03
UrsCy6qIGoo_c_01
UrsCy6qIGoo_c_02
UrsCy6qIGoo_c_03
yn9WN9lsHRE_c_01
yn9WN9lsHRE_c_02
yn9WN9lsHRE_c_03
                 diarization error rate   total correct correct false alarm false alarm missed detection missed detection confusion confusion
                                      %                       %                       %                                 %                   %
item                                                                                                                                         
1j20qq1JyX4_c_01                  56.07  155.05   79.73   51.42       11.61        7.49            41.29            26.63     34.03     21.95
1j20qq1JyX4_c_02                  73.09  227.81   76.10   33.40       14.79        6.49            62.04            27.23     89.68     39.36
1j20qq1JyX4_c_03                  47.79  197.26  120.24   60.95       17.25        8.74            51.29            26.00     25.73     13.05
2qQs3Y9OJX0_c_01                  71.68   89.26   45.78   51.29       20.50       22.97             4.78             5.35     38.70     43.36
2qQs3Y9OJX0_c_02                  54.71  116.06   70.22   60.50       17.65       15.21             5.17             4.46     40.67     35.04
2qQs3Y9OJX0_c_03                  38.63  147.43  112.18   76.09       21.71       14.73             7.49             5.08     27.75     18.82
4ZpjKfu6Cl8_c_01                  76.55  141.59   50.29   35.51       17.08       12.06            48.30            34.11     43.01     30.38
4ZpjKfu6Cl8_c_02                  61.16  154.92   76.65   49.48       16.48       10.64            19.76            12.75     58.50     37.76
4ZpjKfu6Cl8_c_03                  60.39  112.29   61.84   55.07       17.36       15.46             6.62             5.89     43.83     39.03
5milLu-6bWI_c_01                  40.48  174.41  122.25   70.09       18.45       10.58            34.13            19.57     18.03     10.34
5milLu-6bWI_c_02                  38.67  217.06  144.07   66.38       10.96        5.05            40.90            18.84     32.08     14.78
5milLu-6bWI_c_03                  48.41  221.49  128.15   57.86       13.88        6.27            35.66            16.10     57.69     26.04
7YpF6DntOYw_c_01                  77.89  132.86   38.94   29.31        9.57        7.20            34.23            25.76     59.69     44.93
7YpF6DntOYw_c_02                  65.06   54.12   20.90   38.62        1.99        3.67            10.69            19.76     22.53     41.62
7YpF6DntOYw_c_03                  30.36   66.24   49.61   74.89        3.48        5.25             5.34             8.06     11.29     17.05
BCiuXAuCKAU_c_01                  81.56  206.56   40.79   19.75        2.69        1.30           134.50            65.11     31.27     15.14
BCiuXAuCKAU_c_02                  39.81  154.10  100.66   65.32        7.90        5.13            31.49            20.44     21.95     14.24
BCiuXAuCKAU_c_03                  65.23  207.37   74.60   35.97        2.50        1.21           104.94            50.61     27.83     13.42
HKjR70GCRPE_c_01                  39.66  146.56   99.23   67.71       10.80        7.37            17.56            11.98     29.76     20.31
HKjR70GCRPE_c_02                  53.45  145.10   78.74   54.26       11.19        7.71            21.85            15.06     44.52     30.68
HKjR70GCRPE_c_03                  48.76  165.78   94.52   57.02        9.58        5.78            13.79             8.32     57.47     34.67
IKdBLciu_-A_c_01                  40.86  127.60   82.66   64.78        7.20        5.64            12.50             9.80     32.43     25.42
IKdBLciu_-A_c_02                  76.47   95.71   30.36   31.72        7.83        8.19            34.04            35.56     31.32     32.72
IKdBLciu_-A_c_03                  75.08   98.63   30.23   30.65        5.65        5.73            45.46            46.09     22.95     23.26
KHHgQ_Pe4cI_c_01                  59.61  180.62   77.06   42.66        4.10        2.27            94.07            52.08      9.49      5.25
KHHgQ_Pe4cI_c_02                  80.26  119.56   28.32   23.69        4.72        3.95            52.71            44.09     38.52     32.22
KHHgQ_Pe4cI_c_03                  71.13  156.28   49.97   31.97        4.84        3.10            67.17            42.98     39.14     25.05
PmElx9ZVByw_c_01                  36.28  142.53   97.65   68.51        6.83        4.79            19.44            13.64     25.44     17.85
PmElx9ZVByw_c_02                  12.17  147.22  135.56   92.08        6.25        4.25            10.29             6.99      1.38      0.93
PmElx9ZVByw_c_03                  33.07  120.01   85.89   71.57        5.56        4.64            11.42             9.51     22.71     18.92
a5mEmM6w_ks_c_01                  32.67  235.73  168.96   71.68       10.24        4.35            23.26             9.87     43.51     18.46
a5mEmM6w_ks_c_02                  28.46  185.80  138.76   74.68        5.83        3.14            32.07            17.26     14.98      8.06
a5mEmM6w_ks_c_03                  21.97  130.15  106.87   82.11        5.31        4.08            10.52             8.08     12.77      9.81
kMy-6RtoOVU_c_01                  46.92  185.77  111.10   59.80       12.49        6.72            63.19            34.02     11.48      6.18
kMy-6RtoOVU_c_02                  64.10  121.57   59.77   49.16       16.12       13.26            21.32            17.54     40.48     33.30
kMy-6RtoOVU_c_03                  62.85  111.45   69.68   62.52       28.28       25.37            21.00            18.84     20.78     18.64
qrkff49p4E4_c_01                  25.92  147.36  114.56   77.74        5.40        3.67            17.20            11.67     15.59     10.58
qrkff49p4E4_c_02                  14.62  139.38  124.93   89.63        5.92        4.25             9.60             6.89      4.86      3.49
qrkff49p4E4_c_03                  44.47  160.17   96.23   60.08        7.30        4.56            15.56             9.72     48.38     30.20
zC5Fh2tTS1U_c_01                  69.91  193.38  108.60   56.16       50.41       26.07            27.77            14.36     57.01     29.48
zC5Fh2tTS1U_c_02                  80.97  172.54   64.62   37.45       31.78       18.42            18.31            10.61     89.61     51.94
zC5Fh2tTS1U_c_03                  70.11  240.12   98.61   41.07       26.85       11.18            80.99            33.73     60.52     25.21
zR725veL-DI_c_01                  30.94  190.05  138.15   72.69        6.90        3.63            34.50            18.15     17.40      9.16
zR725veL-DI_c_02                  40.77  215.43  134.40   62.39        6.80        3.16            34.93            16.21     46.10     21.40
zR725veL-DI_c_03                  30.22  199.67  145.74   72.99        6.40        3.21            33.29            16.67     20.65     10.34
IzvOYVMltkI_c_01                  31.04  156.71  118.05   75.33        9.99        6.37            10.78             6.88     27.88     17.79
IzvOYVMltkI_c_02                  54.12  191.14  110.94   58.04       23.24       12.16            12.37             6.47     67.82     35.48
IzvOYVMltkI_c_03                  27.29  172.52  136.86   79.33       11.41        6.61             9.16             5.31     26.51     15.36
UrsCy6qIGoo_c_01                  50.94  122.69   78.13   63.68       17.94       14.62            31.51            25.69     13.04     10.63
UrsCy6qIGoo_c_02                  53.50  125.06   63.68   50.92        5.53        4.42            11.91             9.52     49.47     39.56
UrsCy6qIGoo_c_03                  40.51  197.16  123.02   62.40        5.74        2.91            15.89             8.06     58.25     29.54
yn9WN9lsHRE_c_01                  48.64  188.10  103.01   54.77        6.41        3.41            51.11            27.17     33.98     18.07
yn9WN9lsHRE_c_02                  53.40  156.18   84.15   53.88       11.38        7.29            48.51            31.06     23.52     15.06
yn9WN9lsHRE_c_03                  65.34  196.37   79.54   40.51       11.47        5.84            38.86            19.79     77.97     39.71
TOTAL                             50.42 8556.01 4881.54   57.05      639.56        7.47          1752.51            20.48   1921.95     22.46
[1;34mwandb[0m: 🚀 View run [33mmodel_2_dihard_50e_lr1em4[0m at: [34mhttps://wandb.ai/pichenygroup/both/runs/yn4ifhq1[0m
[1;34mwandb[0m: Find logs at: [1;35mexperiments/wandb/run-20250121_185125-yn4ifhq1/logs[0m
